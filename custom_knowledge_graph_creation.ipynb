{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMIjOJoFETV3"
   },
   "source": [
    "# Custom Knowledge Graph Creation\n",
    "\n",
    "In this example, a custom knowledge graph is created from wikipedia documents. We use a custom knowledge graph extractor:\n",
    "\n",
    "```python\n",
    "kg_extractor = DynamicLLMPathExtractor(\n",
    "    llm=Settings.llm,\n",
    "    max_triplets_per_chunk=20,\n",
    "    num_workers=4,\n",
    "    allowed_entity_types=[\n",
    "        \"IDEAS\",\n",
    "        \"TECHNOLOGIES\",\n",
    "        \"FRAMEWORKS\",\n",
    "        \"TECHNIQUES\",\n",
    "        \"USE_CASES\",\n",
    "    ],\n",
    "    allowed_relation_types=[\"CREATED_BY\", \"IMPLEMENTED_IN\", \"USED_BY\", \"HELPS_WITH\"],\n",
    ")\n",
    "```\n",
    "\n",
    "## NebulaGraph Property Graph Index\n",
    "NebulaGraph is an open-source distributed graph database built for super large-scale graphs with milliseconds of latency.\n",
    "\n",
    "If you already have an existing graph, please skip to the end of this notebook.\n",
    "\n",
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™.\n",
    "\n",
    "```python\n",
    "%pip install llama-index-graph-stores-nebula\n",
    "%pip install llama-index-llms-vertex\n",
    "%pip install llama-index-embeddings-vertex\n",
    "%pip install llama-index\n",
    "```\n",
    "\n",
    "\n",
    "Before we start the `Knowledge Graph RAG QueryEngine` demo, let's first get ready for basic preparation of Llama Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "n_EAJgGuETV4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730827193.918877  257055 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730827194.968899  257055 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "# For Vertex\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import logging\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "from vertexai.generative_models import HarmBlockThreshold, HarmCategory, SafetySetting\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "\n",
    "# Import the Secret Manager client library.\n",
    "from google.cloud import secretmanager\n",
    "\n",
    "load_dotenv()  # this loads the .env script for use below\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "LOCATION = os.getenv(\"LOCATION\")\n",
    "\n",
    "# try to get the secret manager stored public IP\n",
    "# Create the Secret Manager client.\n",
    "client = secretmanager.SecretManagerServiceClient()\n",
    "\n",
    "# Access the secret version.\n",
    "try:\n",
    "    response = client.access_secret_version(\n",
    "        request={\"name\": \"projects/679926387543/secrets/nebula-ip/versions/latest\"}\n",
    "    )\n",
    "\n",
    "    # Print the secret payload.\n",
    "    #\n",
    "    # WARNING: Do not print the secret in a production environment - this\n",
    "    # snippet is showing how to access the secret material.\n",
    "    payload = response.payload.data.decode(\"UTF-8\")\n",
    "\n",
    "    NEBULA_SERVER_ADDRESS = payload\n",
    "except:\n",
    "    print(\"no secret found, using 127.0.0.1\")\n",
    "    NEBULA_SERVER_ADDRESS = \"127.0.0.1\"\n",
    "\n",
    "credentials = google.auth.default(quota_project_id=PROJECT_ID)[0]\n",
    "request = google.auth.transport.requests.Request()\n",
    "credentials.refresh(request)\n",
    "\n",
    "safety_config = [\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=HarmBlockThreshold.BLOCK_NONE,\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=HarmBlockThreshold.BLOCK_NONE,\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=HarmBlockThreshold.BLOCK_NONE,\n",
    "    ),\n",
    "]\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ")  # logging.DEBUG for more verbose output\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.vertex import Vertex\n",
    "from llama_index.embeddings.vertex import VertexTextEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = Vertex(\n",
    "    temperature=0,\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    credentials=credentials,\n",
    "    safety_settings=safety_config,\n",
    ")\n",
    "Settings.embed_model = VertexTextEmbedding(\n",
    "    model_name=\"text-embedding-004\", credentials=credentials\n",
    ")\n",
    "Settings.chunk_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Asyncio needed for async ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOa2pw90ETV4"
   },
   "source": [
    "## Prepare for NebulaGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "uryq3yLCETV4",
    "outputId": "56bb7aba-6c0d-42ff-b2be-80b2255d7053"
   },
   "outputs": [],
   "source": [
    "space_name = \"rag\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7OqK9SDETV5"
   },
   "source": [
    "Then we could instiatate a `NebulaGraphStore`, in order to create a `StorageContext`'s `graph_store` as it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ngql extension is already loaded. To reload it, use:\n",
      "  %reload_ext ngql\n",
      "\u001b[1;3;38;2;0;135;107m[OK] Connection Pool Created\u001b[0m\n",
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n",
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext ngql\n",
    "%ngql --address $NEBULA_SERVER_ADDRESS --port 9669 --user root --password <password>\n",
    "%ngql CREATE SPACE IF NOT EXISTS $space_name(vid_type=FIXED_STRING(256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **One time Operation to Load the DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "OylzdX8HETV5"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "from llama_index.graph_stores.nebula import NebulaPropertyGraphStore\n",
    "\n",
    "graph_store = NebulaPropertyGraphStore(\n",
    "    space=space_name, overwrite=True, url=f\"nebula://{NEBULA_SERVER_ADDRESS}:9669\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yk4PWOtLETV5"
   },
   "source": [
    "Here, we assumed to have the same Knowledge Graph from [this turtorial](https://gpt-index.readthedocs.io/en/latest/examples/query_engine/knowledge_graph_query_engine.html#optional-build-the-knowledge-graph-with-llamaindex)\n",
    "\n",
    "Let's follow on this tutorial:\n",
    "\n",
    "# With the help of Llama Index and LLM defined, we could build Knowledge Graph from given documents.\n",
    "\n",
    "If we have a Knowledge Graph on NebulaGraphStore already, this step could be skipped\n",
    "\n",
    "Load data from Wikipedia for \"Guardians of the Galaxy Vol. 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import download_loader\n",
    "\n",
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "\n",
    "loader = WikipediaReader()\n",
    "\n",
    "documents = loader.load_data(\n",
    "    pages=[\"Retrieval-augmented generation\"], auto_suggest=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, Generate a KnowledgeGraphIndex with NebulaGraph as graph_store\n",
    "Then, we will create a KnowledgeGraphIndex to enable Graph based RAG, apart from that, we have a Knowledge Graph up and running for other purposes, too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores.simple import SimpleVectorStore\n",
    "\n",
    "vec_store = SimpleVectorStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use custom graph entity and relationships\n",
    "\n",
    "You can define custom entities and relationships with `PropertyGraphIndex`, using either the `DynamicLLMPathExtractor` [link](https://docs.llamaindex.ai/en/stable/module_guides/indexing/lpg_index_guide/#dynamicllmpathextractor), or the more rigid `SchemaLLMPathExtractor` [link](https://docs.llamaindex.ai/en/stable/module_guides/indexing/lpg_index_guide/#schemallmpathextractor)\n",
    "\n",
    "Here we are going to create a custom knowledge graph about retreival augment generation (sourced from wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.property_graph import DynamicLLMPathExtractor\n",
    "\n",
    "kg_extractor = DynamicLLMPathExtractor(\n",
    "    llm=Settings.llm,\n",
    "    max_triplets_per_chunk=20,\n",
    "    num_workers=4,\n",
    "    allowed_entity_types=[\n",
    "        \"IDEAS\",\n",
    "        \"TECHNOLOGIES\",\n",
    "        \"FRAMEWORKS\",\n",
    "        \"TECHNIQUES\",\n",
    "        \"USE_CASES\",\n",
    "    ],\n",
    "    allowed_relation_types=[\"CREATED_BY\", \"IMPLEMENTED_IN\", \"USED_BY\", \"HELPS_WITH\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad124ca6d004a76864af52d7b98d448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.88it/s]\n",
      "Extracting implicit paths: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 18586.28it/s]\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s]\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 26.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.indices.property_graph import PropertyGraphIndex\n",
    "\n",
    "index = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    property_graph_store=graph_store,\n",
    "    vector_store=vec_store,\n",
    "    show_progress=True,\n",
    "    kg_extractor=kg_extractor,  # this can take a list!\n",
    ")\n",
    "\n",
    "index.storage_context.vector_store.persist(\"./data/nebula_vec_store.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-hJiV2VETV5"
   },
   "source": [
    "# Loading from an existing graph\n",
    "**Important** Go here if skipping data creation step above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "JFe9yeTNETV5"
   },
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.nebula import NebulaPropertyGraphStore\n",
    "from llama_index.core.indices.property_graph import PropertyGraphIndex\n",
    "\n",
    "\n",
    "graph_store = NebulaPropertyGraphStore(\n",
    "    space=space_name, url=f\"nebula://{NEBULA_SERVER_ADDRESS}:9669\"\n",
    ")\n",
    "\n",
    "from llama_index.core.vector_stores.simple import SimpleVectorStore\n",
    "\n",
    "vec_store = SimpleVectorStore.from_persist_path(\"./data/nebula_vec_store.json\")\n",
    "\n",
    "index = PropertyGraphIndex.from_existing(\n",
    "    property_graph_store=graph_store,\n",
    "    vector_store=vec_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the graph is created, we can explore it with [jupyter-nebulagraph](https://github.com/wey-gu/jupyter_nebulagraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n",
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>e</th>\n",
       "      <th>q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\"Retrieval\" :Props__{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"77a5817c-27b8-4eb6-af01-3e06553d9332\"} :Node__{label: \"entity\"} :Entity__{name: \"Retrieval\"})</td>\n",
       "      <td>(\"Retrieval\")-[:Relation__@0{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, label: \"Uses\", last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"d2968930-9650-4b9a-8e17-65aab1d4fbdc\"}]-&gt;(\"Document retriever\")</td>\n",
       "      <td>(\"Document retriever\" :Props__{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"d2968930-9650-4b9a-8e17-65aab1d4fbdc\"} :Node__{label: \"entity\"} :Entity__{name: \"Document retriever\"})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(\"Retrieval\" :Props__{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"77a5817c-27b8-4eb6-af01-3e06553d9332\"} :Node__{label: \"entity\"} :Entity__{name: \"Retrieval\"})</td>\n",
       "      <td>(\"Retrieval\")-[:Relation__@0{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, label: \"Is\", last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"d2968930-9650-4b9a-8e17-65aab1d4fbdc\"}]-&gt;(\"Process\")</td>\n",
       "      <td>(\"Process\" :Props__{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"d2968930-9650-4b9a-8e17-65aab1d4fbdc\"} :Node__{label: \"entity\"} :Entity__{name: \"Process\"})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(\"Retrieval\" :Props__{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"77a5817c-27b8-4eb6-af01-3e06553d9332\"} :Node__{label: \"entity\"} :Entity__{name: \"Retrieval\"})</td>\n",
       "      <td>(\"Retrieval\")-[:Relation__@0{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, label: \"Be\", last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"77a5817c-27b8-4eb6-af01-3e06553d9332\"}]-&gt;(\"Slow\")</td>\n",
       "      <td>(\"Slow\" :Props__{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"77a5817c-27b8-4eb6-af01-3e06553d9332\"} :Node__{label: \"entity\"} :Entity__{name: \"Slow\"})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                  p                                                                                                                                                                                                                                                                                                                                                                                         e                                                                                                                                                                                                                                                                                                                                                                                                                   q\n",
       "0  (\"Retrieval\" :Props__{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"77a5817c-27b8-4eb6-af01-3e06553d9332\"} :Node__{label: \"entity\"} :Entity__{name: \"Retrieval\"})  (\"Retrieval\")-[:Relation__@0{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, label: \"Uses\", last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"d2968930-9650-4b9a-8e17-65aab1d4fbdc\"}]->(\"Document retriever\")  (\"Document retriever\" :Props__{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"d2968930-9650-4b9a-8e17-65aab1d4fbdc\"} :Node__{label: \"entity\"} :Entity__{name: \"Document retriever\"})\n",
       "1  (\"Retrieval\" :Props__{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"77a5817c-27b8-4eb6-af01-3e06553d9332\"} :Node__{label: \"entity\"} :Entity__{name: \"Retrieval\"})               (\"Retrieval\")-[:Relation__@0{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, label: \"Is\", last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"d2968930-9650-4b9a-8e17-65aab1d4fbdc\"}]->(\"Process\")                        (\"Process\" :Props__{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"d2968930-9650-4b9a-8e17-65aab1d4fbdc\"} :Node__{label: \"entity\"} :Entity__{name: \"Process\"})\n",
       "2  (\"Retrieval\" :Props__{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"77a5817c-27b8-4eb6-af01-3e06553d9332\"} :Node__{label: \"entity\"} :Entity__{name: \"Retrieval\"})                  (\"Retrieval\")-[:Relation__@0{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, label: \"Be\", last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"77a5817c-27b8-4eb6-af01-3e06553d9332\"}]->(\"Slow\")                              (\"Slow\" :Props__{_node_content: __NULL__, _node_type: __NULL__, creation_date: __NULL__, doc_id: __NULL__, document_id: __NULL__, file_name: __NULL__, file_path: __NULL__, file_size: __NULL__, file_type: __NULL__, last_modified_date: __NULL__, ref_doc_id: __NULL__, triplet_source_id: \"77a5817c-27b8-4eb6-af01-3e06553d9332\"} :Node__{label: \"entity\"} :Entity__{name: \"Slow\"})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query some random Relationships with Cypher\n",
    "\n",
    "%ngql USE $space_name;\n",
    "%ngql MATCH (p)-[e]->(q) RETURN p, e, q LIMIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n",
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunk__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entity__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Node__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Props__</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name\n",
       "0   Chunk__\n",
       "1  Entity__\n",
       "2    Node__\n",
       "3   Props__"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAGS = %ngql SHOW TAGS\n",
    "%ngql SHOW TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n",
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Relation__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__meta__node_label__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__meta__rel_label__</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name\n",
       "0            Relation__\n",
       "1  __meta__node_label__\n",
       "2   __meta__rel_label__"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDGES = %ngql SHOW EDGES\n",
    "%ngql SHOW EDGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n",
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n",
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index the schema for querying\n",
    "%ngql CREATE TAG INDEX IF NOT EXISTS entity_index on Entity__();\n",
    "%ngql CREATE TAG INDEX IF NOT EXISTS props_index on Props__();\n",
    "%ngql CREATE EDGE INDEX IF NOT EXISTS relation_index on Relation__();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p.Entity__.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Augment query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heavy cost training runs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p.Entity__.name\n",
       "0             Augment query\n",
       "1  Heavy cost training runs"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql MATCH q=(p:Node__:Entity__) RETURN p.Entity__.name LIMIT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('34.55.198.242', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>relation</th>\n",
       "      <th>dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information</td>\n",
       "      <td>Fed into</td>\n",
       "      <td>Llm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chunking</td>\n",
       "      <td>Break up</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chunking</td>\n",
       "      <td>Find</td>\n",
       "      <td>Details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chunking</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>File format based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunking</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>Fixed length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunking</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>Overlap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunking</td>\n",
       "      <td>Involves</td>\n",
       "      <td>Strategies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunking</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>Syntax based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llms</td>\n",
       "      <td>Include</td>\n",
       "      <td>Hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Can be improved</td>\n",
       "      <td>Centroid searches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Can be improved</td>\n",
       "      <td>Dot products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Can be improved</td>\n",
       "      <td>Nearest neighbors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Document retriever</td>\n",
       "      <td>Selects</td>\n",
       "      <td>Relevant documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Document retriever</td>\n",
       "      <td>Is called</td>\n",
       "      <td>Select relevant documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Relevant documents</td>\n",
       "      <td>Used</td>\n",
       "      <td>Augment query</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   src         relation                       dest\n",
       "0          Information         Fed into                        Llm\n",
       "1             Chunking         Break up                       Data\n",
       "2             Chunking             Find                    Details\n",
       "3             Chunking         Strategy          File format based\n",
       "4             Chunking         Strategy               Fixed length\n",
       "5             Chunking         Strategy                    Overlap\n",
       "6             Chunking         Involves                 Strategies\n",
       "7             Chunking         Strategy               Syntax based\n",
       "8                 Llms          Include              Hallucination\n",
       "9          Performance  Can be improved          Centroid searches\n",
       "10         Performance  Can be improved               Dot products\n",
       "11         Performance  Can be improved          Nearest neighbors\n",
       "12  Document retriever          Selects         Relevant documents\n",
       "13  Document retriever        Is called  Select relevant documents\n",
       "14  Relevant documents             Used              Augment query"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql MATCH p=(v:Entity__)-[r]->(t:Entity__) RETURN v.Entity__.name AS src, r.label AS relation, t.Entity__.name AS dest LIMIT 15;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"nebulagraph_cell_128.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x3387bf020>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<class 'pyvis.network.Network'> |N|=16 |E|=15"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ng_draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rendered output should look like this:\n",
    "\n",
    "![](./graph_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yc2N1xD1ETV5"
   },
   "source": [
    "# Querying and Retrieval\n",
    "1. Getting a simple graph from a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_retriever = index.as_retriever(\n",
    "    include_text=False,  # include source text in returned nodes, default True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCdHZRKUETV5",
    "outputId": "566480bd-60c7-44ff-e59a-4438f955d9bc"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Chunking -> Break up -> Data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Chunking -> Find -> Details"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Chunking -> Strategy -> File format based"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Chunking -> Strategy -> Fixed length"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Chunking -> Strategy -> Overlap"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Chunking -> Involves -> Strategies"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Chunking -> Strategy -> Syntax based"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Rag -> Eliminate -> Challenges"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Rag -> Uses -> Information"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Rag -> Grants -> Information retrieval capabilities"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Rag -> Modifies -> Interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Rag -> Can be used on -> Semi-structured data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Rag -> Can be used on -> Structured data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Rag -> Is -> Technique"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Rag -> Can be used on -> Unstructured data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Progressive data augmentation -> Use -> Methods"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Augmentation modules -> Incorporates -> Augmentation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Augmentation modules -> Have abilities -> Expanding queries"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Augmentation modules -> Use -> Memory and self-improvement"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Retriever using inverse cloze task -> Pre-train -> Methods"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "nodes = subgraph_retriever.retrieve(\n",
    "    \"Tell me about chunking in retrieval augmented generation\",\n",
    ")\n",
    "node_text = \"\"\n",
    "for node in nodes:\n",
    "    display(Markdown(f\"{node.text}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Getting a NL query over the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    streaming=True,\n",
    "    include_text=True,  # include source text in returned nodes, default True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking is a strategy used in retrieval augmented generation to break up data into smaller units called vectors. This allows the retriever to efficiently find relevant details within the data. There are several chunking strategies, including fixed length with overlap, syntax-based chunking, and file format-based chunking. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Tell me about chunking in retrieval augmented generation\",\n",
    ")\n",
    "display(Markdown(response.print_response_stream()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check on source nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='b5e73cba-d219-4f0a-9b04-32bf32af7d40', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='75229858', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5878f62255c46891cdc11c5953435e70e6522322cec36216e0147761467a710e'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e7d4e4b3-1434-4731-9709-ed170a9def49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7fe778aa2a357082c3de2557e5b78c8468a9bc0cffa0af79cae1d11da97ad31a')}, text=\"Here are some facts extracted from the provided text:\\n\\nChunking -> Break up -> Data\\nChunking -> Find -> Details\\nChunking -> Strategy -> File format based\\nChunking -> Strategy -> Fixed length\\nChunking -> Strategy -> Overlap\\nChunking -> Involves -> Strategies\\nChunking -> Strategy -> Syntax based\\nRag -> Eliminate -> Challenges\\nRag -> Includes -> Giving factual information\\nRag -> Uses -> Information\\nRag -> Grants -> Information retrieval capabilities\\nRag -> Modifies -> Interactions\\nRag -> Allows -> Llms\\nRag -> Process -> Made up\\nRag -> Includes -> Providing chatbot access\\nRag -> Can be used on -> Semi-structured data\\nRag -> Can be used on -> Structured data\\nRag -> Is -> Technique\\nRag -> Can be used on -> Unstructured data\\n\\n=== Chunking ===\\n\\nChunking involves various strategies for breaking up the data into vectors so the retriever can find details in it.\\n\\nThree types of chunking strategy are:\\n\\nFixed length with overlap.  This is fast and easy.  Overlapping consecutive chunks help to maintain semantic context across chunks.\\nSyntax based chunks can break document up by sentences.  Libraries such as spaCy or NLTK can also help.\\nFile format based chunking.  Certain file types have natural chunks built in and it's best to respect them.  For example, code files are best chunked and vectorized as whole functions or classes.  HTML files should leave <table> or base64 encoded <img> elements intact.  Similar considerations should be taken for pdf files.  Libraries such as Unstructured or Langchain can assist with this method.\\n\\n\\n== Challenges ==\\nIf the external data source is large, retrieval can be slow. The use of RAG does not completely eliminate the general challenges faced by LLMs, including hallucination.\\n\\n\\n== References ==\", mimetype='text/plain', start_char_idx=4357, end_char_idx=5372, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=1.0),\n",
       " NodeWithScore(node=TextNode(id_='69b78dbd-e3ec-4600-a20b-541bc65f4b20', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='75229858', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5878f62255c46891cdc11c5953435e70e6522322cec36216e0147761467a710e'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ccfa0b55-5162-4394-8d5e-bd4e93711a84', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='80ab8a47fc15d4a0d99faac2aa3ac62e9fa47e6faa9828ff142a6841534a4a97'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e7d4e4b3-1434-4731-9709-ed170a9def49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7fe778aa2a357082c3de2557e5b78c8468a9bc0cffa0af79cae1d11da97ad31a')}, text='Here are some facts extracted from the provided text:\\n\\nProgressive data augmentation -> Use -> Methods\\nRetriever using inverse cloze task -> Pre-train -> Methods\\n\\n=== Retriever-centric methods ===\\nThese methods focus on improving the quality of hits from the vector database:\\n\\npre-train the retriever using the Inverse Cloze Task.\\nprogressive data augmentation.  The method of Dragon samples difficult negatives to train a dense vector  retriever.\\nUnder supervision, train the retriever for a given generator.  Given a prompt and the desired answer, retrieve the top-k vectors, and feed those vectors into the generator to achieve a perplexity score for the correct answer.  Then minimize the KL-divergence between the observed retrieved vectors probability and LM likelihoods to adjust the retriever.\\nuse reranking to train the retriever.\\n\\n\\n=== Language model ===\\n\\nBy redesigning the language model with the retriever in mind, a 25-times smaller network can get comparable perplexity as its much larger counterparts.  Because it is trained from scratch, this method (Retro) incurs the heavy cost of training runs that the original RAG scheme avoided.  The hypothesis is that by giving domain knowledge during training, Retro needs less focus on domain and can devote its smaller weight resources only on language semantics.  The redesigned language model is shown here.  \\nIt has been reported that Retro is not reproducible, so modifications were made to make it so.  The more reproducible version is called Retro++ and includes in-context RAG.', mimetype='text/plain', start_char_idx=2972, end_char_idx=4354, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5870722474204825),\n",
       " NodeWithScore(node=TextNode(id_='b5e73cba-d219-4f0a-9b04-32bf32af7d40', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='75229858', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5878f62255c46891cdc11c5953435e70e6522322cec36216e0147761467a710e'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e7d4e4b3-1434-4731-9709-ed170a9def49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7fe778aa2a357082c3de2557e5b78c8468a9bc0cffa0af79cae1d11da97ad31a')}, text=\"Here are some facts extracted from the provided text:\\n\\nChunking -> Break up -> Data\\nChunking -> Find -> Details\\nChunking -> Strategy -> File format based\\nChunking -> Strategy -> Fixed length\\nChunking -> Strategy -> Overlap\\nChunking -> Involves -> Strategies\\nChunking -> Strategy -> Syntax based\\n\\n=== Chunking ===\\n\\nChunking involves various strategies for breaking up the data into vectors so the retriever can find details in it.\\n\\nThree types of chunking strategy are:\\n\\nFixed length with overlap.  This is fast and easy.  Overlapping consecutive chunks help to maintain semantic context across chunks.\\nSyntax based chunks can break document up by sentences.  Libraries such as spaCy or NLTK can also help.\\nFile format based chunking.  Certain file types have natural chunks built in and it's best to respect them.  For example, code files are best chunked and vectorized as whole functions or classes.  HTML files should leave <table> or base64 encoded <img> elements intact.  Similar considerations should be taken for pdf files.  Libraries such as Unstructured or Langchain can assist with this method.\\n\\n\\n== Challenges ==\\nIf the external data source is large, retrieval can be slow. The use of RAG does not completely eliminate the general challenges faced by LLMs, including hallucination.\\n\\n\\n== References ==\", mimetype='text/plain', start_char_idx=4357, end_char_idx=5372, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5659269455979616),\n",
       " NodeWithScore(node=TextNode(id_='59d3a92e-b240-4dcb-9ea3-56133ef4ec61', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='75229858', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5878f62255c46891cdc11c5953435e70e6522322cec36216e0147761467a710e'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='60a45b02-07cc-4243-918a-34793d0fdc18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3fed69980f3086d91588336d928b06c290d2b477d58e733cfbdaea644f4c845d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ccfa0b55-5162-4394-8d5e-bd4e93711a84', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='80ab8a47fc15d4a0d99faac2aa3ac62e9fa47e6faa9828ff142a6841534a4a97')}, text=\"Here are some facts extracted from the provided text:\\n\\nAugmentation modules -> Incorporates -> Augmentation\\nAugmentation modules -> Have abilities -> Expanding queries\\nAugmentation modules -> Use -> Memory and self-improvement\\n\\n=== Retrieval ===\\nGiven a user query, a document retriever is first called to select the most relevant documents which will be used to augment the query. This comparison can be done using a variety of methods, which depend in part on the type of indexing used.\\n\\n\\n=== Augmentation ===\\nThe model feeds this relevant retrieved information into the LLM via prompt engineering of the user's original query. Newer implementations (as of 2023) can also incorporate specific augmentation modules with abilities such as expanding queries into multiple domains, and using memory and self-improvement to learn from previous retrievals.\\n\\n\\n=== Generation ===\\nFinally, the LLM can generate output based on both the query and the retrieved documents. Some models incorporate extra steps to improve output such as the re-ranking of retrieved information, context selection and fine tuning.\\n\\n\\n== Improvements ==\\nImprovements to the basic process above can be applied at different stages in the RAG flow. \\n\\n\\n=== Encoder ===\\nThese methods center around the encoding of text as either dense or sparse vectors. Sparse vectors, used to encode the identity of a word, are typically dictionary length and contain almost all zeros. Dense vectors, used to encode meaning, are much smaller and contain far fewer zeros. Several enhancements can be made in the way similarities are calculated in the vector stores (databases).  \\n\\nPerformance can be improved with faster dot products, approximate nearest neighors, or centroid searches.\\nAccuracy can be improved with Late Interactions.\\nHybrid vectors: dense vector representations can be combined with sparse one-hot vectors in order to use the faster sparse dot products rather than the slower dense ones.  Other methods can combine sparse methods (BM25, SPLADE) with dense ones like DRAGON.\", mimetype='text/plain', start_char_idx=1157, end_char_idx=2969, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5566778385558382)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'> Source (Node id: b5e73cba-d219-4f0a-9b04-32bf32af7d40): Here are some facts extracted from the provided text:\\n\\nChunking -> Break up -> Data\\nChunking -> F...\\n\\n> Source (Node id: 69b78dbd-e3ec-4600-a20b-541bc65f4b20): Here are some facts extracted from the provided text:\\n\\nProgressive data augmentation -> Use -> Me...\\n\\n> Source (Node id: b5e73cba-d219-4f0a-9b04-32bf32af7d40): Here are some facts extracted from the provided text:\\n\\nChunking -> Break up -> Data\\nChunking -> F...\\n\\n> Source (Node id: 59d3a92e-b240-4dcb-9ea3-56133ef4ec61): Here are some facts extracted from the provided text:\\n\\nAugmentation modules -> Incorporates -> Au...'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.get_formatted_sources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using a hybrid query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    include_text=True,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    embedding_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Chunking is a strategy used in retrieval augmented generation to break up data into smaller units, called vectors. This allows the retriever to efficiently find specific details within the data. There are several chunking strategies, including fixed length with overlap, syntax-based chunking, and file format-based chunking. \n",
       "</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Tell me about chunking in retrieval augmented generation\",\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use `TextToCypherRetriever` to generate queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.property_graph import TextToCypherRetriever\n",
    "\n",
    "\n",
    "DEFAULT_RESPONSE_TEMPLATE = (\n",
    "    \"Generated Cypher query:\\n{query}\\n\\n\" \"Cypher Response:\\n{response}\"\n",
    ")\n",
    "DEFAULT_ALLOWED_FIELDS = [\"text\", \"label\", \"type\"]\n",
    "\n",
    "DEFAULT_TEXT_TO_CYPHER_TEMPLATE = (index.property_graph_store.text_to_cypher_template,)\n",
    "\n",
    "\n",
    "cypher_retriever = TextToCypherRetriever(\n",
    "    index.property_graph_store,\n",
    "    # customize the LLM, defaults to Settings.llm\n",
    "    llm=Settings.llm,\n",
    "    # customize the text-to-cypher template.\n",
    "    # Requires `schema` and `question` template args\n",
    "    text_to_cypher_template=index.property_graph_store.text_to_cypher_template,\n",
    "    # customize how the cypher result is inserted into\n",
    "    # a text node. Requires `query` and `response` template args\n",
    "    response_template=DEFAULT_RESPONSE_TEMPLATE,\n",
    "    # an optional callable that can clean/verify generated cypher\n",
    "    cypher_validator=None,\n",
    "    # allowed fields in the resulting\n",
    "    allowed_output_field=DEFAULT_ALLOWED_FIELDS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = index.property_graph_store.get_schema_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Node properties:\\n\\nRelationship properties:\\n\\nThe relationships:\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "('NebulaGraph query failed:', \"SyntaxError: syntax error near ```cypher'\", 'Statement:', '```cypher\\nMATCH (c:Concept {name: \"chunking\"})<-[:HAS_CONCEPT]-(d:Document)<-[:DESCRIBES]-(r:Resource {name: \"RAG\"})\\nRETURN c, d, r\\n```', 'Params:', None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[43mcypher_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproperty_graph_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_to_cypher_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTell me about chunking and how it applies to RAG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSCHEMA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gcp-graph-rag/.venv/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/gcp-graph-rag/.venv/lib/python3.12/site-packages/llama_index/core/base/base_retriever.py:245\u001b[0m, in \u001b[0;36mBaseRetriever.retrieve\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mas_trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    242\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mRETRIEVE,\n\u001b[1;32m    243\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[1;32m    244\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[0;32m--> 245\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_recursive_retrieval(query_bundle, nodes)\n\u001b[1;32m    247\u001b[0m         retrieve_event\u001b[38;5;241m.\u001b[39mon_end(\n\u001b[1;32m    248\u001b[0m             payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mNODES: nodes},\n\u001b[1;32m    249\u001b[0m         )\n",
      "File \u001b[0;32m~/gcp-graph-rag/.venv/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/gcp-graph-rag/.venv/lib/python3.12/site-packages/llama_index/core/indices/property_graph/sub_retrievers/base.py:142\u001b[0m, in \u001b[0;36mBasePGRetriever._retrieve\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[NodeWithScore]:\n\u001b[0;32m--> 142\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_from_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_text \u001b[38;5;129;01mand\u001b[39;00m nodes:\n\u001b[1;32m    144\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_source_text(nodes)\n",
      "File \u001b[0;32m~/gcp-graph-rag/.venv/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/gcp-graph-rag/.venv/lib/python3.12/site-packages/llama_index/core/indices/property_graph/sub_retrievers/text_to_cypher.py:147\u001b[0m, in \u001b[0;36mTextToCypherRetriever.retrieve_from_graph\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    139\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_to_cypher_template,\n\u001b[1;32m    141\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m    142\u001b[0m     question\u001b[38;5;241m=\u001b[39mquestion,\n\u001b[1;32m    143\u001b[0m )\n\u001b[1;32m    145\u001b[0m parsed_cypher_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_generated_cypher(response)\n\u001b[0;32m--> 147\u001b[0m query_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_cypher_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m cleaned_query_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_query_output(query_output)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummarize_response:\n",
      "File \u001b[0;32m~/gcp-graph-rag/.venv/lib/python3.12/site-packages/llama_index/graph_stores/nebula/nebula_property_graph.py:550\u001b[0m, in \u001b[0;36mNebulaPropertyGraphStore.structured_query\u001b[0;34m(self, query, param_map)\u001b[0m\n\u001b[1;32m    548\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mexecute_parameter(query, build_param_map(param_map))\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mis_succeeded():\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNebulaGraph query failed:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    552\u001b[0m         result\u001b[38;5;241m.\u001b[39merror_msg(),\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatement:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    554\u001b[0m         query,\n\u001b[1;32m    555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    556\u001b[0m         param_map,\n\u001b[1;32m    557\u001b[0m     )\n\u001b[1;32m    558\u001b[0m full_result \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    559\u001b[0m     {\n\u001b[1;32m    560\u001b[0m         key: result\u001b[38;5;241m.\u001b[39mrow_values(row_index)[i]\u001b[38;5;241m.\u001b[39mcast_primitive()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(result\u001b[38;5;241m.\u001b[39mrow_size())\n\u001b[1;32m    564\u001b[0m ]\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msanitize_query_output:\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;66;03m# Not applicable for NebulaGraph for now though\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: ('NebulaGraph query failed:', \"SyntaxError: syntax error near ```cypher'\", 'Statement:', '```cypher\\nMATCH (c:Concept {name: \"chunking\"})<-[:HAS_CONCEPT]-(d:Document)<-[:DESCRIBES]-(r:Resource {name: \"RAG\"})\\nRETURN c, d, r\\n```', 'Params:', None)"
     ]
    }
   ],
   "source": [
    "nodes = cypher_retriever.retrieve(\n",
    "    index.property_graph_store.text_to_cypher_template.format(\n",
    "        question=\"Tell me about chunking and how it applies to RAG\",\n",
    "        schema=str(SCHEMA),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 753c3a00-4b9d-49cc-842f-3644dceeb50b\n",
      "Text: Generated Cypher query: MATCH (m:Entity__ {name: \"Guardians of\n",
      "the Galaxy 3\"})<-[:Relation__]-(p:Props__) RETURN p   Cypher Response:\n",
      "[]\n",
      "Score:  1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup \n",
    "%ngql\n",
    "CLEAR/DROP SPACE $space_name; "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
